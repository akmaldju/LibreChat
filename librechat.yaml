version: 1.0.8
 
cache: true
 
interface:
  # Privacy policy settings
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true
 
  # Terms of service
  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true
 
registration:
  socialLogins: ["discord", "facebook", "github", "google", "openid"]
 
endpoints:
  custom:
 
    # # Anyscale
    # - name: "Anyscale"
    #   apiKey: "${ANYSCALE_API_KEY}"
    #   baseURL: "https://api.endpoints.anyscale.com/v1"
    #   models:
    #     default: [
    #       "meta-llama/Llama-2-7b-chat-hf",
    #       ]
    #     fetch: true
    #   titleConvo: true
    #   titleModel: "meta-llama/Llama-2-7b-chat-hf"
    #   summarize: false
    #   summaryModel: "meta-llama/Llama-2-7b-chat-hf"
    #   forcePrompt: false
    #   modelDisplayLabel: "Anyscale"
 
    # APIpie
    # - name: "APIpie"
    #   apiKey: "${APIPIE_API_KEY}"
    #   baseURL: "https://apipie.ai/v1/"
    #   models:
    #     default: [
    #       "gpt-4",
    #       "gpt-4-turbo",
    #       "gpt-3.5-turbo",
    #       "claude-3-opus",
    #       "claude-3-sonnet",
    #       "claude-3-haiku",
    #       "llama-3-70b-instruct",
    #       "llama-3-8b-instruct",
    #       "gemini-pro-1.5",
    #       "gemini-pro",
    #       "mistral-large",
    #       "mistral-medium",
    #       "mistral-small",
    #       "mistral-tiny",
    #       "mixtral-8x22b",
    #       ]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "gpt-3.5-turbo"
    #   dropParams: ["stream"]
 
    #cohere
    # - name: "cohere"
    #   apiKey: "${COHERE_API_KEY}"
    #   baseURL: "https://api.cohere.ai/v1"
    #   models:
    #     default: ["command-r","command-r-plus","command-light","command-light-nightly","command","command-nightly"]
    #     fetch: false
    #   modelDisplayLabel: "cohere"
    #   titleModel: "command"
    #   dropParams: ["stop", "user", "frequency_penalty", "presence_penalty", "temperature", "top_p"]
 
    # Fireworks
    # - name: "Fireworks"
    #   apiKey: "${FIREWORKS_API_KEY}"
    #   baseURL: "https://api.fireworks.ai/inference/v1"
    #   models:
    #     default: [
    #       "accounts/fireworks/models/mixtral-8x7b-instruct",
    #       ]
    #     fetch: true
    #   titleConvo: true
    #   titleModel: "accounts/fireworks/models/llama-v2-7b-chat"
    #   summarize: false
    #   summaryModel: "accounts/fireworks/models/llama-v2-7b-chat"
    #   forcePrompt: false
    #   modelDisplayLabel: "Fireworks"
    #   dropParams: ["user"]
 
    # OpenRouter.ai
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "google/gemini-2.0-flash-exp:free",
          "--NEW--",
          "meta-llama/llama-4-maverick:free",
          "meta-llama/llama-4-scout:free",
          "openrouter/optimus-alpha",
          "deepseek/deepseek-v3-base:free",
          "bytedance-research/ui-tars-72b:free",
          "google/gemini-2.5-pro-exp-03-25:free",
          "nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
          "nvidia/llama-3.3-nemotron-super-49b-v1:free",
          "nvidia/llama-3.1-nemotron-nano-8b-v1:free",
          "--Google--",
          # "google/gemini-2.0-flash-exp:free",
          "google/gemini-2.0-pro-exp-02-05:free",
          "google/gemini-2.0-flash-lite-preview-02-05:free",
          "google/gemini-2.0-flash-thinking-exp:free",
          "google/gemma-3-27b-it:free",
          "google/learnlm-1.5-pro-experimental:free",
          "--DeepSeek--",
          "deepseek/deepseek-r1:free",
          "deepseek/deepseek-r1-zero:free",
          "deepseek/deepseek-chat-v3-0324:free",
          "--Meta--",
          "meta-llama/llama-3.2-90b-vision-instruct:free",
          "meta-llama/llama-3.2-11b-vision-instruct:free",
          "meta-llama/llama-3.2-3b-instruct:free",
          "meta-llama/llama-3.2-1b-instruct:free",
          "meta-llama/llama-3.1-405b-instruct:free",
          "meta-llama/llama-3.1-70b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "--Qwen--",
          "qwen/qwen2.5-vl-32b-instruct:free",
          "qwen/qwq-32b:free",
          "qwen/qwen2.5-vl-72b-instruct:free",
          "qwen/qwen-vl-plus:free",
          "--Others--",
          "featherless/qwerky-72b:free",
          "open-r1/olympiccoder-32b:free",
          "mistralai/mistral-small-3.1-24b-instruct:free",
          "rekaai/reka-flash-3:free",
          "moonshotai/moonlight-16b-a3b-instruct:free",
          "openchat/openchat-7b:free",
          "undi95/toppy-m-7b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "gryphe/mythomax-l2-13b:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free",
          "nvidia/llama-3.1-nemotron-70b-instruct:free",
          "cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
          "cognitivecomputations/dolphin3.0-mistral-24b:free",
          "--Outdated--",
          "google/gemini-pro-1.5-exp",
          "google/gemini-flash-1.5-exp",
          "google/gemini-flash-1.5-8b-exp",
          "google/gemma-2-9b-it:free",
          "meta-llama/llama-3-8b-instruct:free",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "qwen/qwen-2-7b-instruct:free",
          "nousresearch/deephermes-3-llama-3-8b-preview:free",
          "mistralai/mistral-7b-instruct:free"
          ]
        fetch: false
      titleConvo: true
      titleModel: "google/gemini-2.0-flash-exp:free"
      summarize: false
      summaryModel: "google/gemini-2.0-flash-exp:free"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    - name: "OpenRouter Backup"
      apiKey: "${OPENROUTER_KEY_2}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "google/gemini-2.0-flash-exp:free",
          "--NEW--",
          "meta-llama/llama-4-maverick:free",
          "meta-llama/llama-4-scout:free",
          "openrouter/optimus-alpha",
          "deepseek/deepseek-v3-base:free",
          "bytedance-research/ui-tars-72b:free",
          "google/gemini-2.5-pro-exp-03-25:free",
          "nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
          "nvidia/llama-3.3-nemotron-super-49b-v1:free",
          "nvidia/llama-3.1-nemotron-nano-8b-v1:free",
          "--Google--",
          # "google/gemini-2.0-flash-exp:free",
          "google/gemini-2.0-pro-exp-02-05:free",
          "google/gemini-2.0-flash-lite-preview-02-05:free",
          "google/gemini-2.0-flash-thinking-exp:free",
          "google/gemma-3-27b-it:free",
          "google/learnlm-1.5-pro-experimental:free",
          "--DeepSeek--",
          "deepseek/deepseek-r1:free",
          "deepseek/deepseek-r1-zero:free",
          "deepseek/deepseek-chat-v3-0324:free",
          "--Meta--",
          "meta-llama/llama-3.2-90b-vision-instruct:free",
          "meta-llama/llama-3.2-11b-vision-instruct:free",
          "meta-llama/llama-3.2-3b-instruct:free",
          "meta-llama/llama-3.2-1b-instruct:free",
          "meta-llama/llama-3.1-405b-instruct:free",
          "meta-llama/llama-3.1-70b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "--Qwen--",
          "qwen/qwen2.5-vl-32b-instruct:free",
          "qwen/qwq-32b:free",
          "qwen/qwen2.5-vl-72b-instruct:free",
          "qwen/qwen-vl-plus:free",
          "--Others--",
          "featherless/qwerky-72b:free",
          "open-r1/olympiccoder-32b:free",
          "mistralai/mistral-small-3.1-24b-instruct:free",
          "rekaai/reka-flash-3:free",
          "moonshotai/moonlight-16b-a3b-instruct:free",
          "openchat/openchat-7b:free",
          "undi95/toppy-m-7b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "gryphe/mythomax-l2-13b:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free",
          "nvidia/llama-3.1-nemotron-70b-instruct:free",
          "cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
          "cognitivecomputations/dolphin3.0-mistral-24b:free",
          "--Outdated--",
          "google/gemini-pro-1.5-exp",
          "google/gemini-flash-1.5-exp",
          "google/gemini-flash-1.5-8b-exp",
          "google/gemma-2-9b-it:free",
          "meta-llama/llama-3-8b-instruct:free",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "qwen/qwen-2-7b-instruct:free",
          "nousresearch/deephermes-3-llama-3-8b-preview:free",
          "mistralai/mistral-7b-instruct:free"
          ]
        fetch: false
      titleConvo: true
      titleModel: "google/gemini-2.0-flash-exp:free"
      summarize: false
      summaryModel: "google/gemini-2.0-flash-exp:free"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter Backup"

    - name: "OpenRouter Own"
      apiKey: "user_provided"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "google/gemini-2.0-flash-exp:free",
          "--NEW--",
          "meta-llama/llama-4-maverick:free",
          "meta-llama/llama-4-scout:free",
          "openrouter/optimus-alpha",
          "deepseek/deepseek-v3-base:free",
          "bytedance-research/ui-tars-72b:free",
          "google/gemini-2.5-pro-exp-03-25:free",
          "nvidia/llama-3.1-nemotron-ultra-253b-v1:free",
          "nvidia/llama-3.3-nemotron-super-49b-v1:free",
          "nvidia/llama-3.1-nemotron-nano-8b-v1:free",
          "--Google--",
          # "google/gemini-2.0-flash-exp:free",
          "google/gemini-2.0-pro-exp-02-05:free",
          "google/gemini-2.0-flash-lite-preview-02-05:free",
          "google/gemini-2.0-flash-thinking-exp:free",
          "google/gemma-3-27b-it:free",
          "google/learnlm-1.5-pro-experimental:free",
          "--DeepSeek--",
          "deepseek/deepseek-r1:free",
          "deepseek/deepseek-r1-zero:free",
          "deepseek/deepseek-chat-v3-0324:free",
          "--Meta--",
          "meta-llama/llama-3.2-90b-vision-instruct:free",
          "meta-llama/llama-3.2-11b-vision-instruct:free",
          "meta-llama/llama-3.2-3b-instruct:free",
          "meta-llama/llama-3.2-1b-instruct:free",
          "meta-llama/llama-3.1-405b-instruct:free",
          "meta-llama/llama-3.1-70b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "--Qwen--",
          "qwen/qwen2.5-vl-32b-instruct:free",
          "qwen/qwq-32b:free",
          "qwen/qwen2.5-vl-72b-instruct:free",
          "qwen/qwen-vl-plus:free",
          "--Others--",
          "featherless/qwerky-72b:free",
          "open-r1/olympiccoder-32b:free",
          "mistralai/mistral-small-3.1-24b-instruct:free",
          "rekaai/reka-flash-3:free",
          "moonshotai/moonlight-16b-a3b-instruct:free",
          "openchat/openchat-7b:free",
          "undi95/toppy-m-7b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "gryphe/mythomax-l2-13b:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free",
          "nvidia/llama-3.1-nemotron-70b-instruct:free",
          "cognitivecomputations/dolphin3.0-r1-mistral-24b:free",
          "cognitivecomputations/dolphin3.0-mistral-24b:free",
          "--Outdated--",
          "google/gemini-pro-1.5-exp",
          "google/gemini-flash-1.5-exp",
          "google/gemini-flash-1.5-8b-exp",
          "google/gemma-2-9b-it:free",
          "meta-llama/llama-3-8b-instruct:free",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "qwen/qwen-2-7b-instruct:free",
          "nousresearch/deephermes-3-llama-3-8b-preview:free",
          "mistralai/mistral-7b-instruct:free"
          ]
        fetch: false
      titleConvo: true
      titleModel: "google/gemini-2.0-flash-exp:free"
      summarize: false
      summaryModel: "google/gemini-2.0-flash-exp:free"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter Own"
 
    # Perplexity
    # - name: "Perplexity"
    #   apiKey: "${PERPLEXITY_API_KEY}"
    #   baseURL: "https://api.perplexity.ai/"
    #   models:
    #     default: [
    #       "mistral-7b-instruct",
    #       "sonar-small-chat",
    #       "sonar-small-online",
    #       "sonar-medium-chat",
    #       "sonar-medium-online"
    #       ]
    #     fetch: false # fetching list of models is not supported
    #   titleConvo: true
    #   titleModel: "sonar-medium-chat"
    #   summarize: false
    #   summaryModel: "sonar-medium-chat"
    #   forcePrompt: false
    #   dropParams: ["stop", "frequency_penalty"]
    #   modelDisplayLabel: "Perplexity"
 
    # ShuttleAI API
    # - name: "ShuttleAI"
    #   apiKey: "${SHUTTLEAI_API_KEY}"
    #   baseURL: "https://api.shuttleai.app/v1"
    #   models:
    #     default: [
    #       "shuttle-1", "shuttle-turbo"
    #       ]
    #     fetch: true
    #   titleConvo: true
    #   titleModel: "gemini-pro"
    #   summarize: false
    #   summaryModel: "llama-summarize"
    #   forcePrompt: false
    #   modelDisplayLabel: "ShuttleAI"
    #   dropParams: ["user"]

    - name: 'HuggingFace'
      apiKey: '${HUGGINGFACE_TOKEN}'
      baseURL: 'https://api-inference.huggingface.co/v1'
      models:
        default: [
          "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
          "--NEW--",
          "Qwen/QwQ-32B",
          "--Google--",
          "google/gemma-1.1-2b-it",
          "google/gemma-1.1-7b-it",
          "--HuggingFace--",
          "HuggingFaceH4/starchat2-15b-v0.1",
          "HuggingFaceH4/zephyr-7b-beta",
          "--Meta--",
          "meta-llama/Llama-3.2-11B-Vision-Instruct",
          "meta-llama/Llama-3.2-3B-Instruct",
          "meta-llama/Llama-3.2-1B-Instruct",
          "--Microsoft--",
          "microsoft/Phi-3.5-mini-instruct",
          "microsoft/Phi-3-mini-4k-instruct",
          "--MistralAI--",
          "mistralai/Mistral-7B-Instruct-v0.3",
          "--Qwen--",
          "Qwen/Qwen2.5-72B-Instruct",
          "Qwen/QwQ-32B-Preview",
          "Qwen/Qwen2.5-Coder-32B-Instruct",
          "--Others--",
          # "black-forest-labs/FLUX.1-dev",
          # "black-forest-labs/FLUX.1-schnell",
          # "XLabs-AI/flux-RealismLora",
          # "CompVis/stable-diffusion-v1-4",
          # "stabilityai/stable-diffusion-xl-base-1.0",
          # "stabilityai/stable-diffusion-3.5-large",
          # "bigcode/starcoder2-15b",
          "codellama/CodeLlama-34b-Instruct-hf",
          "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
          "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
        ]
        # fetch: true
      titleConvo: true
      titleModel: "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
      dropParams: ["top_p"]
      modelDisplayLabel: "HuggingFace"
    # Mistral AI API
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default: [
          "mistral-tiny",
          "mistral-small",
          "mistral-medium",
          "mistral-large-latest"
          ]
        fetch: true
      titleConvo: true
      titleModel: "mistral-tiny"
      modelDisplayLabel: "Mistral"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # groq
    - name: "Groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
          "deepseek-r1-distill-llama-70b",
          "llama-3.2-90b-vision-preview",
          "mixtral-8x7b-32768",
          "llama-guard-3-8b"
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "groq"
    
    # # SambaNova Cloud
    # - name: "SambaNova"
    #   apiKey: "${SAMBANOVA_API_KEY}"
    #   baseURL: "https://api.sambanova.ai/v1"
    #   models:
    #     default: [
    #       "DeepSeek-R1-Distill-Llama-70B",
    #       "--Meta--",
    #       "Meta-Llama-3.1-405B-Instruct",
    #       "Meta-Llama-3.1-70B-Instruct",
    #       "Meta-Llama-3.1-8B-Instruct",
    #       "Meta-Llama-3.2-1B-Instruct",
    #       "Meta-Llama-3.2-3B-Instruct",
    #       "Meta-Llama-3.3-70B-Instruct",
    #       "Meta-Llama-Guard-3-8B",
    #       "--Qwen--",
    #       "Qwen2.5-72B-Instruct",
    #       "Qwen2.5-Coder-32B-Instruct",
    #       "QwQ-32B-Preview",
    #       "--Vision--",
    #       "Llama-3.2-11B-Vision-Instruct",
    #       "Llama-3.2-90B-Vision-Instruct"
    #       ]
    #     fetch: true
    #   titleConvo: true
    #   titleModel: "Meta-Llama-3.1-8B-Instruct"
    #   summarize: false
    #   summaryModel: "DeepSeek-R1-Distill-Llama-70B"
    #   forcePrompt: false
    #   modelDisplayLabel: "SambaNova"

    # together.ai
    - name: "together.ai"
      apiKey: "${TOGETHERAI_API_KEY}"
      baseURL: "https://api.together.xyz"
      models:
        default: [
          "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
          "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
          "meta-llama/Llama-Vision-Free",
          "black-forest-labs/FLUX.1-schnell-Free"
          ]
        fetch: false # fetching list of models is not supported
      titleConvo: true
      titleModel: "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
      summarize: false
      summaryModel: "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free"
      forcePrompt: false
      modelDisplayLabel: "together.ai"