version: 1.0.8
 
cache: true
 
interface:
  # Privacy policy settings
  privacyPolicy:
    externalUrl: 'https://librechat.ai/privacy-policy'
    openNewTab: true
 
  # Terms of service
  termsOfService:
    externalUrl: 'https://librechat.ai/tos'
    openNewTab: true
 
registration:
  socialLogins: ["discord", "facebook", "github", "google", "openid"]
 
endpoints:
  custom:
 
    # # Anyscale
    # - name: "Anyscale"
    #   apiKey: "${ANYSCALE_API_KEY}"
    #   baseURL: "https://api.endpoints.anyscale.com/v1"
    #   models:
    #     default: [
    #       "meta-llama/Llama-2-7b-chat-hf",
    #       ]
    #     fetch: true
    #   titleConvo: true
    #   titleModel: "meta-llama/Llama-2-7b-chat-hf"
    #   summarize: false
    #   summaryModel: "meta-llama/Llama-2-7b-chat-hf"
    #   forcePrompt: false
    #   modelDisplayLabel: "Anyscale"
 
    # APIpie
    # - name: "APIpie"
    #   apiKey: "${APIPIE_API_KEY}"
    #   baseURL: "https://apipie.ai/v1/"
    #   models:
    #     default: [
    #       "gpt-4",
    #       "gpt-4-turbo",
    #       "gpt-3.5-turbo",
    #       "claude-3-opus",
    #       "claude-3-sonnet",
    #       "claude-3-haiku",
    #       "llama-3-70b-instruct",
    #       "llama-3-8b-instruct",
    #       "gemini-pro-1.5",
    #       "gemini-pro",
    #       "mistral-large",
    #       "mistral-medium",
    #       "mistral-small",
    #       "mistral-tiny",
    #       "mixtral-8x22b",
    #       ]
    #     fetch: false
    #   titleConvo: true
    #   titleModel: "gpt-3.5-turbo"
    #   dropParams: ["stream"]
 
    #cohere
    # - name: "cohere"
    #   apiKey: "${COHERE_API_KEY}"
    #   baseURL: "https://api.cohere.ai/v1"
    #   models:
    #     default: ["command-r","command-r-plus","command-light","command-light-nightly","command","command-nightly"]
    #     fetch: false
    #   modelDisplayLabel: "cohere"
    #   titleModel: "command"
    #   dropParams: ["stop", "user", "frequency_penalty", "presence_penalty", "temperature", "top_p"]
 
    # Fireworks
    # - name: "Fireworks"
    #   apiKey: "${FIREWORKS_API_KEY}"
    #   baseURL: "https://api.fireworks.ai/inference/v1"
    #   models:
    #     default: [
    #       "accounts/fireworks/models/mixtral-8x7b-instruct",
    #       ]
    #     fetch: true
    #   titleConvo: true
    #   titleModel: "accounts/fireworks/models/llama-v2-7b-chat"
    #   summarize: false
    #   summaryModel: "accounts/fireworks/models/llama-v2-7b-chat"
    #   forcePrompt: false
    #   modelDisplayLabel: "Fireworks"
    #   dropParams: ["user"]
 
    # OpenRouter.ai
    - name: "OpenRouter"
      apiKey: "${OPENROUTER_KEY}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "google/gemini-2.0-flash-exp:free",
          "--NEW--",
          "qwen/qwen2.5-vl-72b-instruct:free",
          "qwen/qwen-vl-plus:free",
          "nvidia/llama-3.1-nemotron-70b-instruct:free",
          "deepseek/deepseek-r1:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free",
          "--Google--",
          # "google/gemini-2.0-flash-exp:free",
          "google/gemini-2.0-flash-thinking-exp:free",
          "google/gemini-pro-1.5-exp",
          "google/gemini-flash-1.5-exp",
          "google/gemini-flash-1.5-8b-exp",
          "google/learnlm-1.5-pro-experimental:free",
          "google/gemma-2-9b-it:free",
          "--DeepSeek--",
          "deepseek/deepseek-r1:free",
          "--Meta--",
          "meta-llama/llama-3.2-90b-vision-instruct:free",
          "meta-llama/llama-3.2-11b-vision-instruct:free",
          "meta-llama/llama-3.2-3b-instruct:free",
          "meta-llama/llama-3.2-1b-instruct:free",
          "meta-llama/llama-3.1-405b-instruct:free",
          "meta-llama/llama-3.1-70b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "meta-llama/llama-3-8b-instruct:free",
          "--Microsoft--",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "--Others--",
          "mistralai/mistral-7b-instruct:free",
          "qwen/qwen-2-7b-instruct:free",
          "openchat/openchat-7b:free",
          "undi95/toppy-m-7b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "gryphe/mythomax-l2-13b:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free"
          ]
        fetch: false
      titleConvo: true
      titleModel: "google/gemini-2.0-flash-exp:free"
      summarize: false
      summaryModel: "google/gemini-2.0-flash-exp:free"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter"

    - name: "OpenRouter Backup"
      apiKey: "${OPENROUTER_KEY_2}"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "google/gemini-2.0-flash-exp:free",
          "--NEW--",
          "qwen/qwen2.5-vl-72b-instruct:free",
          "qwen/qwen-vl-plus:free",
          "nvidia/llama-3.1-nemotron-70b-instruct:free",
          "deepseek/deepseek-r1:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free",
          "--Google--",
          # "google/gemini-2.0-flash-exp:free",
          "google/gemini-2.0-flash-thinking-exp:free",
          "google/gemini-pro-1.5-exp",
          "google/gemini-flash-1.5-exp",
          "google/gemini-flash-1.5-8b-exp",
          "google/gemini-exp-1206:free",
          "google/learnlm-1.5-pro-experimental:free",
          "google/gemma-2-9b-it:free",
          "--DeepSeek--",
          "deepseek/deepseek-r1:free",
          "--Meta--",
          "meta-llama/llama-3.2-90b-vision-instruct:free",
          "meta-llama/llama-3.2-11b-vision-instruct:free",
          "meta-llama/llama-3.2-3b-instruct:free",
          "meta-llama/llama-3.2-1b-instruct:free",
          "meta-llama/llama-3.1-405b-instruct:free",
          "meta-llama/llama-3.1-70b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "meta-llama/llama-3-8b-instruct:free",
          "--Microsoft--",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "--Others--",
          "mistralai/mistral-7b-instruct:free",
          "qwen/qwen-2-7b-instruct:free",
          "openchat/openchat-7b:free",
          "undi95/toppy-m-7b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "gryphe/mythomax-l2-13b:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free"
          ]
        fetch: false
      titleConvo: true
      titleModel: "google/gemini-2.0-flash-exp:free"
      summarize: false
      summaryModel: "google/gemini-2.0-flash-exp:free"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter Backup"

    - name: "OpenRouter Own"
      apiKey: "user_provided"
      baseURL: "https://openrouter.ai/api/v1"
      models:
        default: [
          "google/gemini-2.0-flash-exp:free",
          "--NEW--",
          "qwen/qwen2.5-vl-72b-instruct:free",
          "qwen/qwen-vl-plus:free",
          "nvidia/llama-3.1-nemotron-70b-instruct:free",
          "deepseek/deepseek-r1:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free",
          "--Google--",
          # "google/gemini-2.0-flash-exp:free",
          "google/gemini-2.0-flash-thinking-exp:free",
          "google/gemini-pro-1.5-exp",
          "google/gemini-flash-1.5-exp",
          "google/gemini-flash-1.5-8b-exp",
          "google/gemini-exp-1206:free",
          # "google/gemini-exp-1121:free",
          # "google/gemini-exp-1114:free",
          "google/learnlm-1.5-pro-experimental:free",
          "google/gemma-2-9b-it:free",
          "--DeepSeek--",
          "deepseek/deepseek-r1:free",
          "--Meta--",
          "meta-llama/llama-3.2-90b-vision-instruct:free",
          "meta-llama/llama-3.2-11b-vision-instruct:free",
          "meta-llama/llama-3.2-3b-instruct:free",
          "meta-llama/llama-3.2-1b-instruct:free",
          "meta-llama/llama-3.1-405b-instruct:free",
          "meta-llama/llama-3.1-70b-instruct:free",
          "meta-llama/llama-3.1-8b-instruct:free",
          "meta-llama/llama-3-8b-instruct:free",
          "--Microsoft--",
          "microsoft/phi-3-medium-128k-instruct:free",
          "microsoft/phi-3-mini-128k-instruct:free",
          "--Others--",
          "mistralai/mistral-7b-instruct:free",
          "qwen/qwen-2-7b-instruct:free",
          "openchat/openchat-7b:free",
          "undi95/toppy-m-7b:free",
          "huggingfaceh4/zephyr-7b-beta:free",
          "gryphe/mythomax-l2-13b:free",
          "sophosympatheia/rogue-rose-103b-v0.2:free"
          ]
        fetch: false
      titleConvo: true
      titleModel: "google/gemini-2.0-flash-exp:free"
      summarize: false
      summaryModel: "google/gemini-2.0-flash-exp:free"
      forcePrompt: false
      modelDisplayLabel: "OpenRouter Own"
 
    # Perplexity
    # - name: "Perplexity"
    #   apiKey: "${PERPLEXITY_API_KEY}"
    #   baseURL: "https://api.perplexity.ai/"
    #   models:
    #     default: [
    #       "mistral-7b-instruct",
    #       "sonar-small-chat",
    #       "sonar-small-online",
    #       "sonar-medium-chat",
    #       "sonar-medium-online"
    #       ]
    #     fetch: false # fetching list of models is not supported
    #   titleConvo: true
    #   titleModel: "sonar-medium-chat"
    #   summarize: false
    #   summaryModel: "sonar-medium-chat"
    #   forcePrompt: false
    #   dropParams: ["stop", "frequency_penalty"]
    #   modelDisplayLabel: "Perplexity"
 
    # ShuttleAI API
    # - name: "ShuttleAI"
    #   apiKey: "${SHUTTLEAI_API_KEY}"
    #   baseURL: "https://api.shuttleai.app/v1"
    #   models:
    #     default: [
    #       "shuttle-1", "shuttle-turbo"
    #       ]
    #     fetch: true
    #   titleConvo: true
    #   titleModel: "gemini-pro"
    #   summarize: false
    #   summaryModel: "llama-summarize"
    #   forcePrompt: false
    #   modelDisplayLabel: "ShuttleAI"
    #   dropParams: ["user"]
 
    # together.ai
    # - name: "together.ai"
    #   apiKey: "${TOGETHERAI_API_KEY}"
    #   baseURL: "https://api.together.xyz"
    #   models:
    #     default: [
    #       "zero-one-ai/Yi-34B-Chat",
    #       "Austism/chronos-hermes-13b",
    #       "DiscoResearch/DiscoLM-mixtral-8x7b-v2",
    #       "Gryphe/MythoMax-L2-13b",
    #       "lmsys/vicuna-13b-v1.5",
    #       "lmsys/vicuna-7b-v1.5",
    #       "lmsys/vicuna-13b-v1.5-16k",
    #       "codellama/CodeLlama-13b-Instruct-hf",
    #       "codellama/CodeLlama-34b-Instruct-hf",
    #       "codellama/CodeLlama-70b-Instruct-hf",
    #       "codellama/CodeLlama-7b-Instruct-hf",
    #       "togethercomputer/llama-2-13b-chat",
    #       "togethercomputer/llama-2-70b-chat",
    #       "togethercomputer/llama-2-7b-chat",
    #       "NousResearch/Nous-Capybara-7B-V1p9",
    #       "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
    #       "NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT",
    #       "NousResearch/Nous-Hermes-Llama2-70b",
    #       "NousResearch/Nous-Hermes-llama-2-7b",
    #       "NousResearch/Nous-Hermes-Llama2-13b",
    #       "NousResearch/Nous-Hermes-2-Yi-34B",
    #       "openchat/openchat-3.5-1210",
    #       "Open-Orca/Mistral-7B-OpenOrca",
    #       "togethercomputer/Qwen-7B-Chat",
    #       "snorkelai/Snorkel-Mistral-PairRM-DPO",
    #       "togethercomputer/alpaca-7b",
    #       "togethercomputer/falcon-40b-instruct",
    #       "togethercomputer/falcon-7b-instruct",
    #       "togethercomputer/GPT-NeoXT-Chat-Base-20B",
    #       "togethercomputer/Llama-2-7B-32K-Instruct",
    #       "togethercomputer/Pythia-Chat-Base-7B-v0.16",
    #       "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
    #       "togethercomputer/RedPajama-INCITE-7B-Chat",
    #       "togethercomputer/StripedHyena-Nous-7B",
    #       "Undi95/ReMM-SLERP-L2-13B",
    #       "Undi95/Toppy-M-7B",
    #       "WizardLM/WizardLM-13B-V1.2",
    #       "garage-bAInd/Platypus2-70B-instruct",
    #       "mistralai/Mistral-7B-Instruct-v0.1",
    #       "mistralai/Mistral-7B-Instruct-v0.2",
    #       "mistralai/Mixtral-8x7B-Instruct-v0.1",
    #       "teknium/OpenHermes-2-Mistral-7B",
    #       "teknium/OpenHermes-2p5-Mistral-7B",
    #       "upstage/SOLAR-10.7B-Instruct-v1.0"
    #       ]
    #     fetch: false # fetching list of models is not supported
    #   titleConvo: true
    #   titleModel: "togethercomputer/llama-2-7b-chat"
    #   summarize: false
    #   summaryModel: "togethercomputer/llama-2-7b-chat"
    #   forcePrompt: false
    #   modelDisplayLabel: "together.ai"

    - name: 'HuggingFace'
      apiKey: '${HUGGINGFACE_TOKEN}'
      baseURL: 'https://api-inference.huggingface.co/v1'
      models:
        default: [
          "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO",
          "--Google--",
          "google/gemma-1.1-2b-it",
          "google/gemma-1.1-7b-it",
          "--HuggingFace--",
          "HuggingFaceH4/starchat2-15b-v0.1",
          "HuggingFaceH4/zephyr-7b-beta",
          "--Meta--",
          "meta-llama/Llama-3.2-11B-Vision-Instruct",
          "meta-llama/Llama-3.2-3B-Instruct",
          "meta-llama/Llama-3.2-1B-Instruct",
          "--Microsoft--",
          "microsoft/Phi-3.5-mini-instruct",
          "microsoft/Phi-3-mini-4k-instruct",
          "--MistralAI--",
          "mistralai/Mistral-7B-Instruct-v0.3",
          "--Qwen--",
          "Qwen/Qwen2.5-72B-Instruct",
          "Qwen/QwQ-32B-Preview",
          "Qwen/Qwen2.5-Coder-32B-Instruct",
          "--Others--",
          # "black-forest-labs/FLUX.1-dev",
          # "black-forest-labs/FLUX.1-schnell",
          # "XLabs-AI/flux-RealismLora",
          # "CompVis/stable-diffusion-v1-4",
          # "stabilityai/stable-diffusion-xl-base-1.0",
          # "stabilityai/stable-diffusion-3.5-large",
          # "bigcode/starcoder2-15b",
          "codellama/CodeLlama-34b-Instruct-hf",
          "deepseek-ai/DeepSeek-R1-Distill-Qwen-32B",
          "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
        ]
        # fetch: true
      titleConvo: true
      titleModel: "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
      dropParams: ["top_p"]
      modelDisplayLabel: "HuggingFace"
    # Mistral AI API
    - name: "Mistral"
      apiKey: "${MISTRAL_API_KEY}"
      baseURL: "https://api.mistral.ai/v1"
      models:
        default: [
          "mistral-tiny",
          "mistral-small",
          "mistral-medium",
          "mistral-large-latest"
          ]
        fetch: true
      titleConvo: true
      titleModel: "mistral-tiny"
      modelDisplayLabel: "Mistral"
      dropParams: ["stop", "user", "frequency_penalty", "presence_penalty"]

    # groq
    - name: "Groq"
      apiKey: "${GROQ_API_KEY}"
      baseURL: "https://api.groq.com/openai/v1/"
      models:
        default: [
          "deepseek-r1-distill-llama-70b",
          "llama-3.2-90b-vision-preview",
          "mixtral-8x7b-32768",
          "llama-guard-3-8b"
          ]
        fetch: false
      titleConvo: true
      titleModel: "mixtral-8x7b-32768"
      modelDisplayLabel: "groq"
    
    # SambaNova Cloud
    - name: "SambaNova"
      apiKey: "${SAMBANOVA_API_KEY}"
      baseURL: "https://api.sambanova.ai/v1"
      models:
        default: [
          "DeepSeek-R1-Distill-Llama-70B",
          "--Meta--",
          "Meta-Llama-3.1-405B-Instruct",
          "Meta-Llama-3.1-70B-Instruct",
          "Meta-Llama-3.1-8B-Instruct",
          "Meta-Llama-3.2-1B-Instruct",
          "Meta-Llama-3.2-3B-Instruct",
          "Meta-Llama-3.3-70B-Instruct",
          "Meta-Llama-Guard-3-8B",
          "--Qwen--",
          "Qwen2.5-72B-Instruct",
          "Qwen2.5-Coder-32B-Instruct",
          "QwQ-32B-Preview",
          "--Vision--",
          "Llama-3.2-11B-Vision-Instruct",
          "Llama-3.2-90B-Vision-Instruct"
          ]
        fetch: true
      titleConvo: true
      titleModel: "Meta-Llama-3.1-8B-Instruct"
      summarize: false
      summaryModel: "DeepSeek-R1-Distill-Llama-70B"
      forcePrompt: false
      modelDisplayLabel: "SambaNova"